## This folder will hold the pre-trained word embeddings.

#### We experiment with three pre-trained word embeddings: <br>
1. Google's _word2vec_ word embeddings: 300 dimensional
2. Stanford's _Glove_ word embeddings
3. Facebook's _fastText_ word embeddings on Wikipedia corpus etc.

__NOTE__: Download and put the files for above here in specified format: <br>
_word2vec_: binary gzipped format <br>
_glove_: txt format <br>
_fastText_: zipped format